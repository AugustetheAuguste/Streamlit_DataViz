# lyon.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import folium
import pydeck as pdk
from folium.plugins import MarkerCluster
from streamlit_folium import folium_static
import matplotlib.pyplot as plt
import seaborn as sns
import bar_chart_race as bcr

def app():

    # Grand titre stylis√©
    st.markdown("<h1 style='text-align: center; font-size: 80px; margin-bottom: 0px; '>Analyse de la DVF √† Lyon ü¶Å</h1>", unsafe_allow_html=True)
    st.markdown("<h1 style= 'border-bottom: 5px solid white;margin-bottom: 100px; '</h1>", unsafe_allow_html=True)


    @st.cache_data

    def load_data():
        # Charger les donn√©es du subset_78 ici, par exemple depuis un fichier CSV
        return pd.read_json('Datasets/finished_subset_lyon_surrounding_all_years.jsonl', lines = True)
    df = load_data()
    df = df.dropna(subset=['latitude', 'longitude'])

    selected_year = st.sidebar.slider("S√©lectionnez une ann√©e:", min_value=2018, max_value=2022)



    # Filtrer le dataframe pour cette ann√©e
    df_year = df[df['Year'] == selected_year]

    # Calculer le nombre total de mutations
    total_mutations = df.shape[0]

    # Calculer le nombre de mutations par an
    mutations_by_year = df['Year'].value_counts().sort_index()

    st.markdown(
        f"""
        <div style='text-align: center; margin-bottom: 20px;'>
            <h2>Nombre total de mutations:</h2>
            <h1><span>{total_mutations}</span></h1>
        </div>
        """,
        unsafe_allow_html=True,
    )



    
    ############################################
    ############################################

    #                   GRAPH

    ############################################
    ############################################



    # Afficher une m√©trique pour chaque ann√©e
    years_to_display = [2018, 2019, 2020, 2021, 2022]
    # Cr√©er des colonnes pour les m√©triques annuelles et les variations
    cols = st.columns(len(years_to_display))

    # Afficher une m√©trique pour chaque ann√©e
    years_to_display = [2018, 2019, 2020, 2021, 2022]

    # Calculer les mutations par ann√©e
    mutations_by_year = df.groupby('Year').size()

    for i, year in enumerate(years_to_display):
        with cols[i]:
            # Afficher les mutations pour l'ann√©e courante
            if year in mutations_by_year.index:
                st.metric(label=f"Mutations en {year}", value=mutations_by_year[year])
            else:
                st.metric(label=f"Mutations en {year}", value=0)

            # Afficher les variations si on n'est pas √† la premi√®re ann√©e
            if i != 0:
                prev_year = years_to_display[i - 1]
                if prev_year in mutations_by_year.index and year in mutations_by_year.index:
                    change = int(mutations_by_year[year] - mutations_by_year[prev_year])
                    percentage_change = (change / mutations_by_year[prev_year]) * 100

                    # S√©lectionnez une fl√®che et une couleur en fonction de la direction du changement
                    if change >= 0:
                        arrow = "‚Üë"
                        color = "green"
                    else:
                        arrow = "‚Üì"
                        color = "red"

                    st.markdown(
                        f"Changement de {prev_year} √† {year}: <span style='font-size:48px; color: {color};'>{arrow}</span> "
                        f"{abs(percentage_change):.2f}% ({change})", 
                        unsafe_allow_html=True
                    )

                    st.write("---")  # Ligne de s√©paration

    
    st.markdown("<div style='font-size: 1.5em;'>Maintenant, nous allons passer √† l'analyse de la demande de valeur fonci√®re √† Lyon. Car en effet, nous devons nous demander o√π c'est que on va d√©m√©nager ? √Ä Lyon. Le march√© de l'immobilier est bien diff√©rent puisqu'il est en plein essor. Il n'a baiss√© que de 5,64% pendant le COVID mais est en train de continuellement progresser. Il stagne autour des 15000 nombres de mutations par an, augmentant donc de 4000 par rapport √† 2018.</div>", unsafe_allow_html=True)
    st.markdown("<h3 style='border-bottom: 2px solid white;margin-bottom: 20px;'></h3>", unsafe_allow_html=True)

    ############################################
    ############################################

    #           O√π sont les endroits o√π il y a le plus de vente?

    ############################################
    ############################################

    st.header("Endroits avec le plus de ventes")
    
    # Cr√©er une carte centr√©e autour de Lyon
    m = folium.Map(location=[45.75, 4.85], zoom_start=12)
    
    # Utilisation de MarkerCluster pour regrouper les ventes proches les unes des autres
    marker_cluster = MarkerCluster().add_to(m)

    # Ajouter des points pour chaque vente
    for idx, row in df.iterrows():
        folium.Marker([row['latitude'], row['longitude']]).add_to(marker_cluster)

    # Afficher la carte
    folium_static(m)

     ############################################
    ############################################

    #           O√π sont les endroits o√π les maisons sont les moins ch√®res?

    ############################################
    ############################################

    st.header("Endroits o√π les maisons sont les moins ch√®res")
    
    # Filtrer pour ne s√©lectionner que les maisons et exclure les rang√©es avec des NaNs dans 'latitude' ou 'longitude'
    df_houses = df[df['Type local'] == 'Maison'].dropna(subset=['latitude', 'longitude'])
    
    # Trier le dataframe par 'Valeur fonciere' et prendre les 100 premiers
    df_cheapest = df_houses.sort_values(by="Valeur fonciere", ascending=True).head(100)

    m_cheapest = folium.Map(location=[45.75, 4.85], zoom_start=12)

    for idx, row in df_cheapest.iterrows():
        folium.Marker(
            [row['latitude'], row['longitude']], 
            popup=f"{row['Valeur fonciere']}‚Ç¨",
            icon=folium.Icon(color="green")
        ).add_to(m_cheapest)

    folium_static(m_cheapest)

    ############################################
    ############################################

    #           O√π sont les endroits o√π les maisons sont les plus ch√®res?

    ############################################
    ############################################

    st.header("Endroits o√π les maisons sont les plus ch√®res")
    
    # Trier le dataframe par 'Valeur fonciere' pour les maisons et prendre les 100 plus chers
    df_expensive = df_houses.sort_values(by="Valeur fonciere", ascending=False).head(100)

    m_expensive = folium.Map(location=[45.75, 4.85], zoom_start=12)

    for idx, row in df_expensive.iterrows():
        folium.Marker(
            [row['latitude'], row['longitude']], 
            popup=f"{row['Valeur fonciere']}‚Ç¨",
            icon=folium.Icon(color="red")
        ).add_to(m_expensive)

    folium_static(m_expensive)



    st.markdown("<div style='font-size: 1.5em;'>Avec les 3 graphes suivants, nous allons essayer de regarder o√π c'est qu'il y a le plus de ventes √† Lyon et ses alentours et o√π se trouvent les maisons les moins ch√®res et les maisons les plus ch√®res. Ces 3 graphes, bien qu'ils nous apportent des informations sur le fait que le centre de Lyon est l'endroit o√π il y a le plus de ventes, que les maisons les moins ch√®res se trouvent au nord de Lyon, et que les maisons les plus ch√®res se trouvent vers Lyon Centre et sa p√©riph√©rie, ne nous permettent pas de voir clairement ce que cela repr√©sente. C'est pourquoi nous devons en faire plus.</div>", unsafe_allow_html=True)
    st.markdown("<h3 style='border-bottom: 2px solid white;margin-bottom: 20px;'></h3>", unsafe_allow_html=True)


    ############################################
    ############################################

    #           Heatmap du nombre de ventes

    ############################################
    ############################################

    st.header("Heatmap du nombre de ventes")

    # Groupez les donn√©es par latitude et longitude et comptez le nombre de ventes pour chaque paire unique
    df_sales_count = df_year.groupby(['latitude', 'longitude']).size().reset_index(name='counts')

    view_state = pdk.ViewState(
        latitude=45.75,
        longitude=4.85,
        zoom=10,
        pitch=0
    )

    heatmap_layer_sales = pdk.Layer(
        "HeatmapLayer",
        df_sales_count,
        get_position=["longitude", "latitude"],
        get_weight="counts",
        radius_pixels=50
    )

    map_sales = pdk.Deck(layers=[heatmap_layer_sales], initial_view_state=view_state)

    st.pydeck_chart(map_sales)


    ############################################
    ############################################

    #           Heatmap du de la valeur fonci√®re

    ############################################
    ############################################

    st.header("Heatmap de la valeur fonci√®re")

    # Groupez les donn√©es par latitude et longitude et sommez la valeur fonci√®re pour chaque paire unique
    df_fonciere_sum = df.groupby(['latitude', 'longitude'])['Valeur fonciere'].sum().reset_index(name='sum_fonciere')

    view_state = pdk.ViewState(
        latitude=45.75,
        longitude=4.85,
        zoom=10,
        pitch=0
    )

    heatmap_layer_fonciere = pdk.Layer(
        "HeatmapLayer",
        df_fonciere_sum,
        get_position=["longitude", "latitude"],
        get_weight="sum_fonciere",
        radius_pixels=50
    )

    map_fonciere = pdk.Deck(layers=[heatmap_layer_fonciere], initial_view_state=view_state)

    st.pydeck_chart(map_fonciere)

    st.markdown("<div style='font-size: 1.5em;'>Avec les 2 heatmaps suivants, nous pouvons identifier les endroits avec le plus de ventes gr√¢ce au heatmap du nombre de ventes et les endroits avec le plus de valeur fonci√®re gr√¢ce au heatmap de la valeur fonci√®re. √Ä partir de ces donn√©es, nous cherchons une maison avec 5 pi√®ces principales ou plus, une surface r√©elle b√¢tie d'environ 150 m¬≤ et un terrain d'environ 500 m¬≤. Nous utilisons alors des heatmaps hexagonales pour rep√©rer les zones avec le plus de ce type de maison. Une zone se d√©marque particuli√®rement : le nord de Lyon. Nous allons donc explorer les communes les plus int√©ressantes pour nous dans cette zone.</div>", unsafe_allow_html=True)
    st.markdown("<h3 style='border-bottom: 2px solid white;margin-bottom: 20px;'></h3>", unsafe_allow_html=True)


     ############################################
    ############################################

    #      Haxagonal chart

    ############################################
    ############################################




    def create_hexagon_layer(dataframe):
        hexagon_layer = pdk.Layer(
            "HexagonLayer",
            dataframe,
            get_position=["longitude", "latitude"],
            auto_highlight=True,
            elevation_scale=2,
            pickable=True,
            elevation_range=[0, 3000],
            extruded=True,
            coverage=0.7,
            radius=1000,
            get_elevation="Valeur fonciere",
            get_fill_color="[255, (1 - elevationValue / 50) * 255, 255, 128]",  # Ajout de 128 pour l'alpha
            # Ajouter tooltips ici
            tooltips=[
                {"html": "<b>Somme Valeur Fonci√®re:</b> {elevationValue}", "style": {"backgroundColor": "steelblue", "color": "white"}}
            ]
        )
        return hexagon_layer
    

    df1  = df[(df['Type local'] == 'Maison') & (df['Nombre pieces principales'] >= 5)]
    df2  = df[(df['Type local'] == 'Maison') & (df['Surface reelle bati'] >= 130) & (df['Surface reelle bati'] <= 170)]
    df3  = df[(df['Type local'] == 'Maison') & (df['Surface terrain'] >= 400) & (df['Surface terrain'] <= 600)]

    df4 =  df[(df['Type local'] == 'Maison') 
              & (df['Nombre pieces principales'] >= 5)
              & (df['Surface reelle bati'] >= 130) 
              & (df['Surface reelle bati'] <= 170)
              & (df['Surface terrain'] >= 400)
              & (df['Surface terrain'] <= 600)]

 # Combinaison des trois crit√®res

    view_state = pdk.ViewState(
           latitude=45.75,
           longitude=4.85,
           zoom=10,
           pitch=45
       )

    # Carte 1
    st.markdown("## Heatmap des maisons avec 5 pi√®ces principales ou plus")
    deck1 = pdk.Deck(layers=[create_hexagon_layer(df1)], initial_view_state=view_state)
    st.pydeck_chart(deck1, use_container_width=True)

    # Carte 2
    st.markdown("## Heatmap des maisons avec une surface r√©elle b√¢tie entre 130 et 170 m¬≤")
    deck2 = pdk.Deck(layers=[create_hexagon_layer(df2)], initial_view_state=view_state)
    st.pydeck_chart(deck2, use_container_width=True)

    # Carte 3
    st.markdown("## Heatmap des maisons avec une surface de terrain entre 400 et 600 m¬≤")
    deck3 = pdk.Deck(layers=[create_hexagon_layer(df3)], initial_view_state=view_state)
    st.pydeck_chart(deck3, use_container_width=True)

    # Carte 4
    st.markdown("## Heatmap des maisons qui combinent les trois crit√®res")
    deck4 = pdk.Deck(layers=[create_hexagon_layer(df4)], initial_view_state=view_state)
    st.pydeck_chart(deck4, use_container_width=True)


    # Mise en page avec 2 colonnes : la premi√®re pour la carte et la seconde pour les metrics des communes

    # Dans la premi√®re colonne : Affichage de la carte
    
    # Cr√©ation d'une carte centr√©e sur la moyenne des latitudes et longitudes des maisons filtr√©es
    m = folium.Map(location=[df4['latitude'].mean(), 
                             df4['longitude'].mean()], 
                   zoom_start=12)

    # Ajout de marqueurs pour chaque maison
    for _, row in df4.iterrows():
        tooltip = f"Commune: {row['Commune']}"
        popup = f"Valeur fonci√®re: {row['Valeur fonciere']} ‚Ç¨"
        folium.Marker(
            location=[row['latitude'], row['longitude']],
            tooltip=tooltip,
            popup=popup
        ).add_to(m)

    # Affichage de la carte dans Streamlit
    folium_static(m)

    # Dans la deuxi√®me colonne : Affichage des metrics des communes

    st.markdown(f"<h2 style='text-align: center;'>üè° Metrics des communes :</h2>", unsafe_allow_html=True)
    # Calcul du nombre de maisons par commune
    # Calcul du nombre de maisons par commune et s√©lection des 5 premi√®res communes avec le plus de maisons
    communes_counts = df4['Commune'].value_counts()
    
    # Utilisation de colonnes pour afficher les metrics en ligne
    cols = st.columns(5)  # Ajustez le nombre en fonction de combien vous voulez afficher sur une ligne
    
    for index, (commune, count) in enumerate(communes_counts.items()):
        if index != 5:
            with cols[index]:
                # Affichage du metric pour chaque commune
                st.metric(label=f"{commune}", value=f"{count} maisons")
        else:
            break


    st.markdown("<div style='font-size: 1.5em;'>Parmi ces communes, nous retrouvons Saint-Genis-Laval, √âcully, Caluire-et-Cuire, Rillieux-le-Pape, entre autres. Ceci n'est que le top 5 parmi de nombreuses autres communes. En conclusion, si nous envisageons de d√©m√©nager, Lyon semble √™tre un excellent choix vu l'essor du march√© immobilier local. Il serait n√©anmoins judicieux d'examiner plus en d√©tail les diff√©rents heatmaps du nombre de ventes et de la valeur fonci√®re pour choisir le lieu id√©al. Nous avons d√©sormais une liste de communes potentiellement int√©ressantes pour nous.</div>", unsafe_allow_html=True)


